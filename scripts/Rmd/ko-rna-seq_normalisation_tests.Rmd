---
title: "RNA-seq - Impact of normalisation on DEG"
output:
  html_document:
    code_folding: hide
    fig_caption: yes
    highlight: zenburn
    self_contained: yes
    theme: cerulean
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    fig_caption: yes
    highlight: zenburn
    toc: yes
    toc_depth: 3
  word_document: default
date: '`r Sys.Date()`'
---

```{r knitr_setup, include=FALSE,  eval=TRUE, echo=FALSE, warning=FALSE}


quick.test <- FALSE ## For debug


knitr::opts_chunk$set(
  fig.path = "figures/",
  echo = FALSE, 
  eval = TRUE, 
  cache = FALSE, 
  message = FALSE, 
  warning = FALSE)
```


```{r load_R_libs, warning=FALSE}
## Load required libraries
required.libraries <- c("knitr",
                        "yaml",
                        "pander", 
                        # "xlsx",
                        "ascii",
                        "xtable",
                        "gplots",
                        "RColorBrewer",
                        "devtools",
                        "stats4bioinfo" ## Generic library from Jacques van Helden
                        )
for (lib in required.libraries) {
  message("\tRequired CRAN library\t", lib)
  if (!require(lib, character.only = TRUE)) {
    install.packages(lib)
    library(lib, character.only = TRUE)
  }
}

# library(gplots, warn.conflicts = FALSE, quietly=TRUE) ## Required for heatmaps.2
#library(RColorBrewer, warn.conflicts = FALSE, quietly=TRUE)


required.bioconductor <- c(
  "edgeR", 
  "DESeq2", 
  "limma", 
#  "SARTools", ## for SERE coefficient
  "GenomicFeatures")

for (lib in required.bioconductor) {
  message("\tRequired BioConductor library\t", lib)
  if (!require(lib, character.only = TRUE)) {
    ## try http:// if https:// URLs are not supported
    source("https://bioconductor.org/biocLite.R")
    biocLite(lib)
  }
  if (!require(lib, character.only = TRUE)) {
    stop("Missing library: ", lib, " could not be installed")
  }
}


## Install SARTools
message("\tRequired devtools library\t", "SARTools")
if (!require("SARTools")) {
  library(devtools)
  install_github("PF2-pasteur-fr/SARTools", build_vignettes = TRUE)
}

```

<!-- !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
PROJECT-SPECIFIC PARAMETERS: THIS PART SHOULD BE ADAPTER FOR EACH PROJECT -->

## Project information

```{r main_parameters}
## Define main parameters to generate this report
dir.main <- "~/ko-rna-seq/" ## Main directory
setwd(dir.main)
message("\tMain directory: ", dir.main)
dir.base <- ".." ## Relative path of the main dir starting from the Rmd file
message("\tBase directory: ", dir.base)


## Load configuration file (YAML-formatted)
configFile <- "metadata/config_RNA-seq.yml"

if (!exists("configFile")) {
  ## The prompt does not seem to work with the Rmd documents
  #   message("Choose the parameter file")
  #   parameter.file <- file.choose()
  stop("This report requires to specify a variable named configFile, containing the path to an YAML-formatted file describing the parameters for this analysis.")
}

parameters <- yaml.load_file(configFile)
message("\tLoaded parameters from file ", configFile)

## parameter.file <- "add_your_path_here"
# parameter.file <- file.path(dir.main, "Rmd/MN-CLOCK_RNA-seq_parameters.R")

# if (!exists("parameter.file")) {
#   ## The prompt does not seem to work with the Rmd documents
#   #   message("Choose the parameter file")
#   #   parameter.file <- file.choose()
#   stop("This report requires to specify a variable named parameter.file, containing the path to an R file describing the parameters for this analysis.")
# }
# source(file=parameter.file)
# message("Loaded parameters from file ", parameter.file)
```

```{r init_directories}
## Check SnakeChunks directory
if (is.null(parameters$dir$snakechunks)) {
  stop("The SnakeChunks directory should be defined in the config file: ", configFile)
} 
dir.SnakeChunks <- file.path(dir.main, parameters$dir$snakechunks)
message("\tDirectory for the Rmd report: ", dir.SnakeChunks)

deg.lib <- file.path(dir.SnakeChunks, "scripts/R-scripts/deg_lib.R")
message("\tLoading DEG library\t", deg.lib)
source(deg.lib)

R.dir <- file.path(dir.SnakeChunks, "scripts/R-scripts/R")
R.files <- c("pc_plot.R", "normalise_count_table.R", "row_stats.R", "feature_colors.R", "volcano_plot.R")
#source(file.path(R.dir, "normalise_count_table.R"))
for (f in R.files) {
  message("\tLoading R file ", f)
  source(file.path(R.dir, f))
}
# TO RESTORE ### source(file.path(R.dir, "pc_plot.R"))

## R markdown (Rmd) directory
if (is.null(parameters$dir$Rmd)) {
  stop("The Rmd directory should be defined in the config file: ", configFile)
} 
dir.Rmd <- parameters$dir$Rmd
message("\tDirectory for the Rmd report: ", dir.Rmd)
dir.create(dir.Rmd, showWarnings = FALSE, recursive = TRUE)
opts_knit$set(base.dir = dir.Rmd) ## Set the working directory for knitr (generating HTML and pdf reports)
# setwd(dir.Rmd) ## Set the working directory for the console


## R markdown (Rmd) directory
if (is.null(parameters$dir$figures)) {
  stop("The figures directory should be defined in the config file: ", configFile)
} 
dir.figures <- parameters$dir$figures
message("\tDirectory for the generic figures: ", dir.figures)
dir.create(dir.figures, showWarnings = FALSE, recursive = TRUE)

## Directory to store differential expression results
dir.DEG <- parameters$dir$diffexpr
message("\tDirectory for differential expresion: ", dir.DEG)
dir.create(dir.DEG, showWarnings = FALSE, recursive = TRUE)

```


<!-- END OF THE PROJECT-SPECIFIC PARAMETERS 
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! -->

```{r print_project_info}

## TEMPORARILY COMMENTED
# kable(data.frame(project.info))

```


```{r default_parameters}
## In this chunk, we define a set of default parameters for the display and the analysis. These parameters can be modified but it is not necessary to adapt them to each project.
if ((!exists("verbosity")) || (is.null(verbosity))) {
  verbosity <- 1
}
if (!exists("export.excel.files")) {
  export.excel.files <- FALSE
}

## Color palette for heatmaps. I like this Red-Blue palette because 
## - it suggests a subjective feeling of warm (high correlation)/cold (low correlation)
## - it can be seen by people suffering from redâ€“green color blindness.
if (!exists("cols.heatmap")) {
  cols.heatmap <- rev(colorRampPalette(brewer.pal(9,"RdBu"))(100))
}

## A trick: to enable log-scaled plots for 0 values, I add an epsilon increment
if (is.null(parameters$DEG$epsilon)) {
 epsilon <- 0.1 # passed to file parameters.R, 2017-03-15
} else {
  epsilon <- parameters$DEG$epsilon
}

## Default method for the selection of the final list of DEG
if (is.null(parameters$DEG$selection_criterion)) {
  DEG.selection.criterion <- "DESeq2"
} else {
  DEG.selection.criterion <- parameters$DEG$selection_criterion
}

## Sample description file
if (is.null(parameters$metadata$samples)) {
  stop("The sample file must be defined in the metadata seection of the yaml config file: ", configFile)
} else {
  sample.description.file <- parameters$metadata$samples
}

## Design file
if (is.null(parameters$metadata$design)) {
  stop("The design file must be defined in the metadata seection of the yaml config file: ", configFile)
} else {
  design.file <- parameters$metadata$design
}

## Count table
count.prefix <- "bowtie2_featureCounts_all"
all.counts.table <- file.path(
  parameters$dir$diffexpr, 
  paste(sep = "", count.prefix, ".tsv"))
all.counts.path <- file.path(dir.main, all.counts.table)
if (!file.exists(all.counts.path)) {
  stop("Feature count table does not exist: ", all.counts.path)
} else {
  message("\tFeature count table: ", all.counts.path)
}


```

## Parameters

| Parameter | Value |
|-----------|-------|
| Sample descriptions | [`r sample.description.file`](`r file.path(dir.base, sample.description.file)`) |
| Analyses descriptions | [`r design.file`](`r file.path(dir.base, design.file)`) |
| Count table | [`r all.counts.table`](`r file.path(dir.base, all.counts.table)`) |

### Thresholds for the differential analysis

```{r threshold_table}
if (is.null(parameters$DEG$thresholds)) {
  message("\tDEG thresholds were not defined in config file -> using default values")
  if (is.null(parameters$DEG)) {
    parameters$DEG <- list()
  }
  parameters$DEG$thresholds <- list(
   padj = 0.05,
   FC = 1.2,
   max.log10.cpm = 8.5)
  
}
thresholds <- parameters$DEG$thresholds
kable(t(as.data.frame(thresholds)), col.names = "Threshold",
        caption = "Thresholds for the selection of differentially expressed genes. ")
```




## Samples


```{r read_samples}
#setwd(dir.main) ## !!!!! I don't understand why I have to reset the working directory at each chunk

## Read the sample description file, which indicates the 
## condition associated to each sample ID.
verbose(paste("Reading sample description file: ", sample.description.file), 2)
sample.desc <- read.delim(
  file.path(dir.main, sample.description.file), sep = "\t", 
  comment = ";", header = TRUE, row.names = 1)
sample.ids <- row.names(sample.desc)

## Experimental conditions
sample.conditions <- as.vector(sample.desc[,1]) ## Condition associated to each sample
names(sample.conditions) <- sample.ids
# print(sample.conditions)

## Build sample labels by concatenating their ID and condition
sample.desc$label <- paste(sep = "_", sample.ids, sample.conditions)

## Define a specific color for each distinct condition
conditions <- unique(sample.conditions) ## Set of distinct conditions
cols.conditions <- brewer.pal(max(3, length(conditions)),"Dark2")[1:length(conditions)]
names(cols.conditions) <- conditions
# print(cols.conditions)

kable(sample.desc, caption = "Sample description table")

## Define a color per sample according to its condition
sample.desc$color <- cols.conditions[sample.conditions]
# names(cols.samples) <- sample.ids
# print(cols.samples)

```



## Design

```{r read_design, warning=FALSE}
# setwd(dir.main) ## !!!!! I don't understand why I have to reset the working directory at each chunk

## Read the design file, which indicates the anlayses to be done.
## Each row specifies one differential expression analysis, which 
## consists in comparing two conditions. 
verbose(paste("Reading design file: ", design.file), 2)
design <- read.delim(file.path(dir.main, design.file), sep = "\t", 
                     comment = ";", header = T, row.names = NULL)
comparison.summary <- design ## Initialize a summary table for each DEG analysis
comparison.summary$prefixes <- paste(sep = "_", design[,1], "vs", design[,2])

## Print out the design table (pairs of conditions to be compared)
kable(comparison.summary, 
      row.names = TRUE, 
      caption = "**Design**. Each row describes one comparison between two conditions.")


```


## Count table

<!-- TO DO: PRINT TABLE WITH SAMPLE IDS PER CONDITION -->



```{r load_count_table}
# setwd(dir.main) ## !!!!! I don't understand why I have to reset the working directory at each chunk

################################################################
## Read the count table
message("Loading count table: ", all.counts.path)
ori.counts <- read.delim(all.counts.path, row.names = 1, sep = "\t")
# names(ori.counts)
# dim(ori.counts)
# View(ori.counts)

## Filter out the rows corresponding to non-assigned counts, 
## e.g. __not_aligned, __ambiguous, __too_low_qAual, __not_aligned
not.feature <- grep(rownames(ori.counts), pattern = "^__")
if (length(not.feature) > 0) {
  all.counts <- ori.counts[-not.feature,]
} else {
  all.counts <- ori.counts
}
# dim(all.counts)

## Just for quick test and  debug: select a random subset of features
if (quick.test) {
  all.counts <- all.counts[sample(x = 1:nrow(all.counts), size = 1000, replace = FALSE),]
}
message("Loaded counts: ", 
        nrow(all.counts), " features x ", 
        ncol(all.counts), " samples")

## Check that the header of all.counts match the sample IDs
ids.not.found <- setdiff(sample.ids, names(all.counts)) ## Identify sample IDs with no column in the count table
if (length(ids.not.found) == length(sample.ids)) {
  colnames(all.counts) <- sample.ids
  ids.not.found <- setdiff(sample.ids, names(all.counts)) ## Identify 
} else if (length(ids.not.found) > 0) {
  stop(length(ids.not.found), " missing columns in count table\t", all.counts.path, 
       "\n\tMissing columns: ", paste(collapse = "; ", ids.not.found))
}

################################################################
## Restrict the count table to the sample IDs found in the sample description file
all.counts <- all.counts[, sample.ids]
# names(all.counts)
# dim(all.counts)

########################################################################
## Treatment of 0 values.
## Add an epsilon to 0 values only, in order to enable log-transform and display on logarithmic axes.
verbose(paste("Treating zero-values by adding epsilon =", epsilon), 2)
all.counts.epsilon <- all.counts
all.counts.epsilon[all.counts == 0] <- epsilon

## Log-transformed data for some plots. 
all.counts.log10 <- log10(all.counts.epsilon)
all.counts.log2 <- log2(all.counts.epsilon)

```



### Sample-wise statistics

The raw counts table ([`r all.counts.table`](`r file.path(dir.base, all.counts.table)`)) 
contains `r nrow(all.counts)` features (rows)) 
and `r ncol(all.counts)` samples (columns)).


```{r sample_statistics}
# setwd(dir.main) ## !!!!! I don't understand why I have to reset the working directory at each chunk

################################################################
## Compute sample-wise statistics on mapped counts
################################################################
#stats.per.sample <- calc.stats.per.sample(sample.desc, all.counts)
# View(stats.per.sample)
stats.per.sample <- cbind(sample.desc, RowStats(all.counts))
stats.per.sample$Mreads <- stats.per.sample$sum / 1e6
# View(stats.per.sample.all)

## Compute statistics ommitting zero values
all.counts.nozero <- all.counts
all.counts.nozero[all.counts.nozero == 0] <- NA
stats.per.sample.nozero <- cbind(sample.desc, RowStats(all.counts.nozero))
stats.per.sample.nozero$Mreads <- stats.per.sample.nozero$sum / 1e6
# names(stats.per.sample)
# View(stats.per.sample.nozero)

################################################################
## Compute the counts per million reads 
################################################################
message("Computing standardized counts")
## Note: the default normalization criterion (scaling by libbrary sum) 
## is questionable because it is stronly sensitive to outliers 
## (very highly expressed genes).  A more robust normalisation criterion 
## is to use the 75th percentile, or the median. We use the median, somewhat arbitrarily, 
## beause it gives a nice alignment on the boxplots.
stdcounts.libsum <- cpm(all.counts.epsilon)    ## Counts per million reads, normalised by library sum
stdcounts.perc75 <- cpm(all.counts.epsilon, lib.size = stats.per.sample$perc75)    ## Counts per million reads, normalised by 75th percentile
stdcounts.perc95 <- cpm(all.counts.epsilon, lib.size = stats.per.sample$perc95)    ## Counts per million reads, normalised by 95th percentile
stdcounts.median <- cpm(all.counts.epsilon, lib.size = stats.per.sample$median)    ## Counts per million reads, normalised by sample-wise median count

## Chose one of the standardization methods to get 
#stdcounts <- stdcounts.median ## Choose one normalization factor for the stdcounts used below
stdcounts <- stdcounts.perc75 ## Choose one normalization factor for the stdcounts used below
stdcounts.log10 <- log10(stdcounts) ## Log-10 transformed stdcounts, xwith the epsilon for 0 counts
stdcounts.log2 <- log2(stdcounts) ## Log-10 transformed stdcounts, with the epsilon for 0 counts


## Export normalized counts (in log2-transformed counts per million reads)
stdcounts.file <- paste(sep = "", count.prefix, "_stdcounts.tsv")
message("\tExporting standardized counts: ", stdcounts.file)
write.table(x = stdcounts, row.names = TRUE, col.names = NA, 
            file = file.path(dir.main, stdcounts.file), sep = "\t", quote = FALSE)

stdcounts.log2.file <- paste(sep = "", count.prefix, "_stdcounts_log2.tsv")
message("\tExporting log2-transformed standardized counts: ", stdcounts.log2.file)
write.table(x = stdcounts.log2, row.names = TRUE, col.names = NA, 
            file = file.path(dir.main, stdcounts.log2.file), sep = "\t", quote = FALSE)


## Detect outliers, i.e. genes with a very high number of reads (hundreds of thousands), most of which result from problems with ribodepletion.
if (is.null(thresholds["max.log10.cpm"])) {
  outlier.threshold <- 8.5 ## Somewhat arbitrary threshold to discard  
} else {
  outlier.threshold <- thresholds["max.log10.cpm"]
}
outliers <- (apply(stdcounts.log10, 1, max) > outlier.threshold)
message("\tDetected ", sum(outliers), " outliers with log10(stdcounts) higher than ", outlier.threshold)
# rownames(stdcounts.log10[outliers,])
# sum(outliers)

## Compute Trimmed Means of M Values (TMM): TO BE DONE
stats.per.sample$cpm.mean <- apply(stdcounts, 2, mean)
stats.per.sample$log2.cpm.mean <- apply(stdcounts.log2, 2, mean)
stats.per.sample$log10.cpm.mean <- apply(stdcounts.log10, 2, mean)

################################################################
## Export stats per sample
#
# names(stats.per.sample)
# head(stats.per.sample)
sample.summary.file <- paste(sep = "", count.prefix, "_summary_per_sample.tsv")
sample.summary.file.path <- file.path(dir.main, paste(sep = "", count.prefix, "_summary_per_sample.tsv"))
message("\tExporting stats per sample\t", sample.summary.file.path)
write.table(x = stats.per.sample, 
            row.names = TRUE, col.names = NA, 
            file = sample.summary.file.path, sep = "\t", quote = FALSE)
# sample.summary.file.xlsx <- paste(sep = "", count.prefix, "_summary_per_sample.xlsx")
# if (export.excel.files) {
#   message(paste(sep = "", "\tSample summary file: ", sample.summary.file.xlsx))
#   write.xlsx(x = stats.per.sample, row.names = TRUE, col.names=TRUE, 
#              file = file.path(dir.main, sample.summary.file.xlsx))
# }

```

```{r print_sample_stats}
## Statistics per sample
stats.per.sample.to.print <- c("Mreads", 
                               "sum", 
                               "min", 
                               "zeros", 
                               "non.null", 
                               "perc05", 
                               "Q1", 
                               "mean", 
                               "median", 
                               "Q3", 
                               "perc95", 
                               "max", 
                               "max.sum.ratio", 
                               "median.mean.ratio", 
                               "fract.below.mean")
setdiff(stats.per.sample.to.print, names(stats.per.sample))

kable(stats.per.sample[stats.per.sample.to.print], digits = 2, 
      format.args = list(big.mark = ",", decimal.mark = "."),
      caption = "Sample-wise statistics (zeros included)")

kable(stats.per.sample.nozero[stats.per.sample.to.print], digits = 2, 
      format.args = list(big.mark = ",", decimal.mark = "."),
      caption = "Sample-wise statistics (zeros excluded)")

```


### Sample sizes

```{r library_sizes_barplot, fig.width=6, fig.height=6, fig.cap="**Barplot of assigned reads per sample. ** Bars indicate the sum of read counts assigned to features (genes) per sample (library)."}
par.ori <- par(no.readonly = TRUE) # Store original parameters
# par(c("mar", "mai"))
# libsize.barplot(
#   stats.per.sample, 
#   plot.file = NULL, 
#   main = "Assigned reads per sample (libsum)")
# par(par.ori) # Restore original parameters
# 
LibsizeBarplot(counts = all.counts, sample.labels = sample.desc$label, sample.colors = sample.desc$color)

```




## Normalisation



```{r normalisation}
norm.methods <- c("mean", "median", "quantile", "TMM", "DESeq2")
norm.comparison <- NormalizeCountTable(
  counts = all.counts, class.labels = sample.conditions, nozero = TRUE, 
  method = norm.methods, quantile = 0.75, log2 = FALSE, epsilon = 0.1, detailed.sample.stats = TRUE,
  verbose = 2)
#names(norm.comparison)
```

```{r size_factors, fig.width=8, fig.height=8, fig.cap="Sample size factors for different normalisation methods. "}
# m <- "median"
size.factors <- data.frame(matrix(nrow = length(sample.ids), ncol = length(norm.methods)))
colnames(size.factors) <- norm.comparison$method.name
rownames(size.factors) <- sample.ids
for (m in norm.comparison$method.name) {
  size.factors[,m] <- norm.comparison[[m]]$size.factor
}
plot(size.factors, main = "Sample size factors", col = sample.desc$color)

```



## Differential analysis

```{r differential_expression_analysis, fig.width=8, fig.height=12}
# setwd(dir.main) ## !!!!! I don't understand why I have to reset the working directory at each chunk

i <- 2
#for (i in 1:nrow(design)) {
  prefix <- list() ## list for output file prefixes

  deg.results <- list()
  
  ## Identify samples for the first condition
  cond1 <- as.vector(design[i,1])  ## First condition for the current comparison
  samples1 <- sample.ids[sample.conditions == cond1]
  if (length(samples1) < 2) {
    stop(paste("Cannot perform differential analysis. The count table contains less than 2 samples for condition", cond1))
  }
  
  ## Identify samples for the second condition
  cond2 <- as.vector(design[i,2])  ## Second condition for the current comparison
  samples2 <- sample.ids[sample.conditions == cond2]
  if (length(samples2) < 2) {
    stop(paste("Cannot perform differential analysis. The count table contains less than 2 samples for condition", cond2))
  }
  
#  stop("HELLO", "\tprefix = ", prefix)
  
  message("\tDifferential analysis\t", i , "/", nrow(design), "\t", cond1, " vs ", cond2)
  
  ## Create a specific result directory for this differential analysis
  comparison.prefix <- comparison.summary$prefixes[i]
  dir.analysis <- file.path(dir.DEG, paste(sep = "", comparison.prefix))
  comparison.summary[i, "dir.analysis"] <- dir.analysis
  dir.create(path = file.path(dir.main, dir.analysis), showWarnings = FALSE, recursive = TRUE)
  dir.figures <- file.path(dir.analysis, "figures")
  comparison.summary[i, "dir.figures"] <- dir.figures
  dir.create(path = file.path(dir.main, dir.figures), showWarnings = FALSE, recursive = TRUE)
  prefix["comparison_file"] <- file.path(dir.analysis, comparison.prefix)
  prefix["comparison_figure"] <- file.path(
    dir.figures, 
    paste(sep = "", comparison.prefix))
#    paste(sep = "", comparison.prefix, "_",  suffix.deg))
  

  ## Select counts for the samples belonging to the two conditions
  current.samples <- c(samples1, samples2)
  current.counts <- data.frame(all.counts[,current.samples])
  # dim(current.counts)  ## For test
  # names(current.counts)
  
  if (sum(!names(current.counts) %in% sample.ids) > 0) {
    stop("Count table contains column names without ID in sample description file.")
  }
  
  ## Define conditions and labels for the samples of the current analysis
  current.conditions <- sample.conditions[current.samples]
  current.labels <- paste(current.conditions, names(current.counts), sep = "_")
  
  result.table <- init.deg.table(stdcounts, samples1, samples2, stats = FALSE) 
# View(result.table)
    
  
  ################################################################
  ## DESeq2 analysis
  ################################################################
  message("\tDESeq2 analysis\t", comparison.prefix)
  deseq2.result <- deseq2.analysis(
    counts = current.counts,
    condition = current.conditions,
    comparison.prefix = comparison.prefix,
    ref.condition = cond2,
    title = comparison.prefix,
    dir.figures = file.path(dir.main, dir.figures))
  deg.results[["DESeq2"]] <- deseq2.result
  # View(deg.results[["DESeq2"]]$result.table)
  result.table <- cbind(
    deseq2.result$result.table, 
    "DESeq2" = deseq2.result$result.table[row.names(result.table),])
  # dim(deseq2.result$result.table)
  # dim(deseq2.result$result.table)
  # names(deseq2.result$result.table)
  # View(deseq2.result$result.table)
  # View(result.table)
  
  
  ## Save the completed DESeq2 result table
  deseq2.result.file <- paste(sep = "_", prefix["comparison_file"], "DESeq2")
  comparison.summary[i,"deseq2"] <- paste(sep = ".", deseq2.result.file, "tsv")
  message("\tExporting DESeq2 result table (tab): ", deseq2.result.file, ".tsv")
  write.table(
    x = deseq2.result$result.table, row.name    = FALSE, 
    file = file.path(dir.main, paste(sep = ".", deseq2.result.file, "tsv")), 
    sep = "\t", quote = FALSE)

  ################################################################
  ## edgeR analysis
  ################################################################
  # norm.method <- "TMM" ## For quick test and debugging
  edgeR.norm.methods <- c("TMM","RLE","upperquartile","none")
  for (norm.method in edgeR.norm.methods) {
    
    edgeR.prefix <- paste(sep = "_", "edgeR", norm.method)
    
    edger.result <- edger.analysis(
      counts = current.counts,
      condition = current.conditions,
      ref.condition = cond2,
      comparison.prefix = comparison.prefix,
      title = comparison.prefix,
      norm.method = norm.method,
      dir.figures = file.path(dir.main, dir.figures))
    deg.results[[edgeR.prefix]] <- edger.result
    
    ## A tricky way to add edgeR with normalisation in column names
    x <- edger.result$result.table
    colnames(x) <- paste(sep = "_", edgeR.prefix, colnames(x))
    # View(x)
    result.table <- cbind(
      result.table, 
      x[row.names(result.table),])
    
    ## Export edgeR result table
    edger.result.file <- paste(sep = "_", prefix["comparison_file"], edgeR.prefix)
    comparison.summary[i,"edger"] <- paste(sep = ".", edger.result.file, "tsv")
    message("\tExporting edgeR result table (tab): ", edger.result.file, ".tsv")
    write.table(x = edger.result$result.table,
                file = file.path(dir.main, paste(sep = ".", edger.result.file, "tsv")), 
                row.names = FALSE, 
                sep = "\t", quote = FALSE)
  }
  
  
  ## Collect results by output statistics
  deg.compa <- list()
  feature.ids <- row.names(current.counts)
  stats.to.collect <- c("padj", "FC", "log2FC")
  for (stat in stats.to.collect) {
    message("Collecting ", stat, " from alternative DEG results. ")
    deg.compa[[stat]] <- data.frame(
      matrix(nrow = nrow(current.counts), 
             ncol = length(names(deg.results))))
    colnames(deg.compa[[stat]]) <- names(deg.results)
    rownames(deg.compa[[stat]]) <- feature.ids
    # deg.name <- "DESeq2"
    for (deg.name in names(deg.results)) {
      deg.compa[[stat]][feature.ids, deg.name] <-  
        as.vector(deg.results[[deg.name]]$result.table[feature.ids,stat])
    }
#    View(deg.compa[[stat]])
  }

  
  ## Define feature colors according to their level of expression (count means)
  feature.scores <- log2(apply(all.counts.epsilon, 1, median))
  
  # hist(feature.scores, breaks = 100)

  # View(deg.compa$padj)
  ## compare DESeq2 and edgeR normalisatio results
  plot(deg.compa$padj, log = "xy", 
#       col = FeatureColors(palette.type = "2col", scores = feature.scores),
       col = FeatureColors(palette.type = "dens", 
                           x = deg.compa$padj[,1], y = deg.compa$padj[,2]),
       main = paste(sep = "", comparison.prefix, "\nAdjusted p-values"))

  plot(deg.compa$log2FC, 
#       col = FeatureColors(palette.type = "2col", scores = feature.scores),
       col = FeatureColors(palette.type = "dens", 
                           x = deg.compa$log2FC[,1], y = deg.compa$log2FC[,2]),
       main = paste(sep = "", comparison.prefix, "\nlog2(fold change)"))

  ## Draw Volcano plots
  # deg.name <- "DESeq2"
  # deg.name <- "edgeR_TMM"
  deg.names <- names(deg.results)
  par.ori <- par(no.readonly = TRUE)
  par(mfrow = n2mfrow(length(deg.names)))
  # deg.name <- "DESeq2"
  for (deg.name in deg.names) {
    deg.result.table <- deg.results[[deg.name]]$result.table
    table(deg.result.table$DEG)
    # head(deg.result.table)
    # names(deg.result.table)
    table(deg.result.table[c("padj_0.05", "FC_1.14", "DEG")])

    # plot(deg.result.table$log2FC, 
    #      -log10(deg.result.table$padj), main = paste(comparison.prefix, deg.name))
    # # # View(deg.result.table)
    VolcanoPlot(multitest.table = deg.result.table,
                main = deg.name,
                effect.size.col = "log2FC",
                control.type = "pvalue",
                alpha = parameters$DEG$thresholds$padj,
                effect.threshold = parameters$DEG$thresholds$FC,
                legend.corner = "topleft")
    
  }
  par(mfrow = c(1,1))
  par(par.ori)
      
# }
```


```{r sessioninfo}
## Print the complete list of libraries + versions used in this session
sessionInfo()
```


```{r job_done}
message("Job done")
```


* * *

